(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{121:function(e,t,n){"use strict";n.d(t,"a",(function(){return u})),n.d(t,"b",(function(){return m}));var r=n(0),o=n.n(r);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var p=o.a.createContext({}),d=function(e){var t=o.a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},u=function(e){var t=d(e.components);return o.a.createElement(p.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return o.a.createElement(o.a.Fragment,{},t)}},b=o.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,i=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=d(n),b=r,m=u["".concat(i,".").concat(b)]||u[b]||s[b]||a;return n?o.a.createElement(m,c(c({ref:t},p),{},{components:n})):o.a.createElement(m,c({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=b;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:r,i[1]=c;for(var p=2;p<a;p++)i[p]=n[p];return o.a.createElement.apply(null,i)}return o.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"},98:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return c})),n.d(t,"rightToc",(function(){return l})),n.d(t,"default",(function(){return d}));var r=n(2),o=n(6),a=(n(0),n(121)),i={id:"providers",title:"Providers in Detail"},c={id:"providers",isDocsHomePage:!1,title:"Providers in Detail",description:"Model Provider",source:"@site/docs/providers.md",permalink:"/docs/providers",editUrl:"https://github.com/skylineprof/skyline/edit/master/website/docs/providers.md",sidebar:"sidebar",previous:{title:"Getting Started",permalink:"/docs/getting-started"},next:{title:"Remote Projects",permalink:"/docs/remote"}},l=[{value:"Model Provider",id:"model-provider",children:[]},{value:"Input Provider",id:"input-provider",children:[]},{value:"Iteration Provider",id:"iteration-provider",children:[]}],p={rightToc:l};function d(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(a.b)("wrapper",Object(r.a)({},p,n,{components:t,mdxType:"MDXLayout"}),Object(a.b)("h3",{id:"model-provider"},"Model Provider"),Object(a.b)("pre",null,Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"def skyline_model_provider() -> torch.nn.Module:\n    pass\n")),Object(a.b)("p",null,"The model provider must take no arguments and return an instance of your model\n(a ",Object(a.b)("inlineCode",{parentName:"p"},"torch.nn.Module"),") that is on the GPU (i.e. you need to call ",Object(a.b)("inlineCode",{parentName:"p"},".cuda()")," on\nthe module before returning it)."),Object(a.b)("h3",{id:"input-provider"},"Input Provider"),Object(a.b)("pre",null,Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"def skyline_input_provider(batch_size: int = 32) -> Tuple:\n    pass\n")),Object(a.b)("p",null,"The input provider must take a single ",Object(a.b)("inlineCode",{parentName:"p"},"batch_size")," argument that has a default\nvalue (the batch size you want to profile with). It must return an iterable\n(does not ",Object(a.b)("em",{parentName:"p"},"have")," to be a ",Object(a.b)("inlineCode",{parentName:"p"},"tuple"),") that contains the arguments that you would\nnormally pass to your model's ",Object(a.b)("inlineCode",{parentName:"p"},"forward")," method. Any ",Object(a.b)("inlineCode",{parentName:"p"},"Tensor"),"s in the returned\niterable must be on the GPU (i.e. you need to call ",Object(a.b)("inlineCode",{parentName:"p"},".cuda()")," on them before\nreturning them)."),Object(a.b)("h3",{id:"iteration-provider"},"Iteration Provider"),Object(a.b)("pre",null,Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"def skyline_iteration_provider(model: torch.nn.Module) -> Callable:\n    pass\n")),Object(a.b)("p",null,"The iteration provider must take a single ",Object(a.b)("inlineCode",{parentName:"p"},"model")," argument, which will be an\ninstance of your model. This provider must return a callable (e.g., a function)\nthat, when invoked, runs a single training iteration."))}d.isMDXComponent=!0}}]);